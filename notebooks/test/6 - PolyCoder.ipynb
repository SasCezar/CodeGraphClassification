{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 12:01:53.551391: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-11 12:01:53.858584: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-11 12:01:54.612782: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-11 12:01:54.612852: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-11 12:01:54.612859: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "No sentence-transformers model found with name /home/sasce/.cache/torch/sentence_transformers/NinedayWang_PolyCoder-2.7B. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /home/sasce/.cache/torch/sentence_transformers/NinedayWang_PolyCoder-2.7B were not used when initializing GPTNeoXModel: ['embed_out.weight']\n",
      "- This IS expected if you are initializing GPTNeoXModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPTNeoXModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"NinedayWang/PolyCoder-2.7B\", device='cpu')\n",
    "model.tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "#Sentences we want to encode. Example:\n",
    "sentence = ['notifyListeners(LexerNoViableAltException e) { String text = _input.getText(Interval.of(_tokenStartCharIndex, _input.index())); String msg = \"token recognition error at: \\'\"+ getErrorDisplay(text) + \"\\'\"; ANTLRErrorListener listener = getErrorListenerDispatch(); listener.syntaxError(this, null, _tokenStartLine, _tokenStartCharPositionInLine, msg, e); }']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['notify', 'Listeners', '(', 'Lexer', 'No', 'V', 'iable', 'Alt', 'Exception', 'Ġe', ')', 'Ġ{', 'ĠString', 'Ġtext', 'Ġ=', 'Ġ_', 'input', '.', 'getText', '(', 'Interval', '.', 'of', '(_', 'token', 'Start', 'Char', 'Index', ',', 'Ġ_', 'input', '.', 'index', '()));', 'ĠString', 'Ġmsg', 'Ġ=', 'Ġ\"', 'token', 'Ġrecogn', 'ition', 'Ġerror', 'Ġat', ':', \"Ġ'\", '\"+', 'Ġget', 'Error', 'Display', '(', 'text', ')', 'Ġ+', 'Ġ\"\\'', '\";', 'ĠAN', 'TL', 'RE', 'rror', 'Listener', 'Ġlistener', 'Ġ=', 'Ġget', 'Error', 'Listener', 'Dispatch', '();', 'Ġlistener', '.', 'syntax', 'Error', '(', 'this', ',', 'Ġnull', ',', 'Ġ_', 'token', 'Start', 'Line', ',', 'Ġ_', 'token', 'Start', 'Char', 'Position', 'In', 'Line', ',', 'Ġmsg', ',', 'Ġe', ');', 'Ġ}']\n"
     ]
    }
   ],
   "source": [
    "input_ids = model.tokenizer(sentence)['input_ids']\n",
    "for tid in input_ids:\n",
    "    print(model.tokenizer.convert_ids_to_tokens(tid))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.41 s ± 20.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "embedding2 = model.encode(sentence)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.3173387 ,  0.20327455,  0.51634157, ..., -0.41659537,\n         0.26449615,  0.5674218 ]], dtype=float32)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embedding2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
